{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796018b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 64) (33000, 64) (33000, 64) (33000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "realCIR = np.load('real.npy')\n",
    "imagCIR = np.load('imag.npy')\n",
    "magCIR = np.load('dataset.npy')\n",
    "GT = np.load('label.npy')\n",
    "\n",
    "print(realCIR.shape, imagCIR.shape, magCIR.shape, GT.shape)\n",
    "\n",
    "tan = np.arctan2(imagCIR, realCIR)\n",
    "diff = tan[:,:63] - tan[:, 1:]\n",
    "diffrence = np.zeros((magCIR.shape[0],magCIR.shape[1]))\n",
    "diffrence[:,1:] = diff\n",
    "\n",
    "array = np.stack([magCIR,diffrence],axis=-1)\n",
    "# array = np.stack([magCIR,tan],axis=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(array, GT, test_size=0.2, shuffle=True, stratify=GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577edc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:26:06.167871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # layer1\n",
    "    tf.keras.layers.Conv1D(96,11, activation=tf.nn.relu,input_shape=(64,2),padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(2,padding='same'),\n",
    "    # layer2\n",
    "    tf.keras.layers.Conv1D(256,5, activation=tf.nn.relu,padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(2,padding='same'),\n",
    "    # layer3\n",
    "    tf.keras.layers.ZeroPadding1D(1),\n",
    "    tf.keras.layers.Conv1D(384,3, activation=tf.nn.relu,padding='same'),\n",
    "    # layer4\n",
    "    tf.keras.layers.ZeroPadding1D(1),\n",
    "    tf.keras.layers.Conv1D(384,3, activation=tf.nn.relu,padding='same'),\n",
    "    # layer5\n",
    "    tf.keras.layers.ZeroPadding1D(1),\n",
    "    tf.keras.layers.Conv1D(256,3, activation=tf.nn.relu,padding='same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # layer6\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # layer7\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # layer8\n",
    "    tf.keras.layers.Dense(6, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d56c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    start = 0.0001\n",
    "    drop = 0.1\n",
    "    epochs_drop = 5\n",
    "    lr = start * (drop ** np.floor((epoch)/epochs_drop))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585b2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc365fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6add6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 1/10\n",
      "825/825 [==============================] - 238s 287ms/step - loss: 3.1087 - accuracy: 0.3394 - val_loss: 1.2915 - val_accuracy: 0.4752 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 2/10\n",
      "825/825 [==============================] - 239s 290ms/step - loss: 1.3400 - accuracy: 0.4417 - val_loss: 1.1243 - val_accuracy: 0.5400 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 3/10\n",
      "825/825 [==============================] - 242s 294ms/step - loss: 1.2111 - accuracy: 0.4977 - val_loss: 0.9964 - val_accuracy: 0.5995 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 4/10\n",
      "825/825 [==============================] - 255s 310ms/step - loss: 1.0991 - accuracy: 0.5450 - val_loss: 0.8972 - val_accuracy: 0.6380 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 5/10\n",
      "825/825 [==============================] - 250s 303ms/step - loss: 0.9974 - accuracy: 0.5897 - val_loss: 0.8369 - val_accuracy: 0.6615 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 6/10\n",
      "825/825 [==============================] - 253s 307ms/step - loss: 0.8585 - accuracy: 0.6460 - val_loss: 0.7464 - val_accuracy: 0.6967 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 7/10\n",
      "825/825 [==============================] - 255s 309ms/step - loss: 0.8101 - accuracy: 0.6678 - val_loss: 0.7251 - val_accuracy: 0.7092 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 8/10\n",
      "825/825 [==============================] - 257s 311ms/step - loss: 0.7793 - accuracy: 0.6823 - val_loss: 0.7091 - val_accuracy: 0.7208 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 9/10\n",
      "825/825 [==============================] - 258s 312ms/step - loss: 0.7609 - accuracy: 0.6879 - val_loss: 0.6932 - val_accuracy: 0.7227 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 10/10\n",
      "825/825 [==============================] - 259s 314ms/step - loss: 0.7380 - accuracy: 0.6967 - val_loss: 0.6778 - val_accuracy: 0.7302 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a4f3a340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10,\n",
    "            validation_data=(X_test, y_test),\n",
    "             callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c73189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 9s 41ms/step - loss: 0.6778 - accuracy: 0.7302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6778316497802734, 0.7301515340805054]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
